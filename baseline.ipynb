{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecb0cc6",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "variables with prefix ``doc_`` contain data from the dataset\n",
    "variables with prefix ``o_`` contain data from own computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a67d9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from petreader.RelationsExtraction import RelationsExtraction\n",
    "from petreader.TokenClassification import TokenClassification\n",
    "from petreader.labels import FLOW, SAME_GATEWAY, AND_GATEWAY, XOR_GATEWAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57474345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\janek\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\patriziobellan--PET\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2 (last modified on Sun Jul  3 12:17:36 2022) since it couldn't be found locally at patriziobellan/PET., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset pet (C:\\Users\\janek\\.cache\\huggingface\\datasets\\patriziobellan___pet\\relations-extraction\\1.0.1\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " _______ _     _ _______       _____  _______ _______      ______  _______ _______ _______ _______ _______ _______\n",
      "    |    |_____| |______      |_____] |______    |         |     \\ |_____|    |    |_____| |______ |______    |   \n",
      "    |    |     | |______      |       |______    |         |_____/ |     |    |    |     | ______| |______    |   \n",
      "                                                                                                                  \n",
      "Discover more at: [https://pdi.fbk.eu/pet-dataset/]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.07157254219055176,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa6c84915444a8f92f3a5e567d1e3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\janek\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\patriziobellan--PET\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2 (last modified on Sun Jul  3 12:17:36 2022) since it couldn't be found locally at patriziobellan/PET., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset pet (C:\\Users\\janek\\.cache\\huggingface\\datasets\\patriziobellan___pet\\token-classification\\1.0.1\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " _______ _     _ _______       _____  _______ _______      ______  _______ _______ _______ _______ _______ _______\n",
      "    |    |_____| |______      |_____] |______    |         |     \\ |_____|    |    |_____| |______ |______    |   \n",
      "    |    |     | |______      |       |______    |         |_____/ |     |    |    |     | ______| |______    |   \n",
      "                                                                                                                  \n",
      "Discover more at: [https://pdi.fbk.eu/pet-dataset/]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04923295974731445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8dbb1614be4d7caa36a898827dcb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relations_dataset = RelationsExtraction()\n",
    "token_dataset = TokenClassification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a868024",
   "metadata": {},
   "source": [
    "## 1 Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6aa06",
   "metadata": {},
   "source": [
    "### 1.1 Read Example Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d77c0222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  doc-1.1  ********************\n",
      "A small company manufactures customized bicycles . Whenever the sales department receives an order , a new process instance is created . A member of the sales department can then reject or accept the order for a customized bike . In the former case , the process instance is finished . In the latter case , the storehouse and the engineering department are informed . The storehouse immediately processes the part list of the order and checks the required quantity of each part . If the part is available in-house , it is reserved . If it is not available , it is back-ordered . This procedure is repeated for each item on the part list . In the meantime , the engineering department prepares everything for the assembling of the ordered bicycle . If the storehouse has successfully reserved or back-ordered every item of the part list and the preparation activity has finished , the engineering department assembles the bicycle . Afterwards , the sales department ships the bicycle to the customer and finishes the process instance .\n",
      "*** activities and NER labels (per sentences) ****\n",
      "[[], [['receives']], [['reject'], ['accept']], [], [['informed']], [['processes'], ['checks']], [['reserved']], [['back-ordered']], [], [['prepares']], [['assembles']], [['ships']]]\n",
      "[[('A', 0, 'O'), ('small', 1, 'O'), ('company', 2, 'O'), ('manufactures', 3, 'O'), ('customized', 4, 'O'), ('bicycles', 5, 'O'), ('.', 6, 'O')], [('Whenever', 0, 'O'), ('the', 1, 'B-Actor'), ('sales', 2, 'I-Actor'), ('department', 3, 'I-Actor'), ('receives', 4, 'B-Activity'), ('an', 5, 'B-Activity Data'), ('order', 6, 'I-Activity Data'), (',', 7, 'O'), ('a', 8, 'O'), ('new', 9, 'O'), ('process', 10, 'O'), ('instance', 11, 'O'), ('is', 12, 'O'), ('created', 13, 'O'), ('.', 14, 'O')], [('A', 0, 'O'), ('member', 1, 'O'), ('of', 2, 'O'), ('the', 3, 'O'), ('sales', 4, 'O'), ('department', 5, 'O'), ('can', 6, 'O'), ('then', 7, 'O'), ('reject', 8, 'B-Activity'), ('or', 9, 'B-XOR Gateway'), ('accept', 10, 'B-Activity'), ('the', 11, 'B-Activity Data'), ('order', 12, 'I-Activity Data'), ('for', 13, 'O'), ('a', 14, 'O'), ('customized', 15, 'O'), ('bike', 16, 'O'), ('.', 17, 'O')], [('In', 0, 'O'), ('the', 1, 'O'), ('former', 2, 'O'), ('case', 3, 'O'), (',', 4, 'O'), ('the', 5, 'O'), ('process', 6, 'O'), ('instance', 7, 'O'), ('is', 8, 'O'), ('finished', 9, 'O'), ('.', 10, 'O')]]\n",
      "************* same gateway relations *************\n",
      "source-head-sentence-ID: 6\n",
      "source-head-word-ID: 0\n",
      "source-entity-type: XOR Gateway\n",
      "source-entity: ['If']\n",
      "target-head-sentence-ID: 7\n",
      "target-head-word-ID: 0\n",
      "target-entity-type: XOR Gateway\n",
      "target-entity: ['If']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "doc_name = token_dataset.GetDocumentName(doc_id)\n",
    "print(f\"  {doc_name}  \".center(50, '*'))\n",
    "doc_text = relations_dataset.GetDocument(doc_id)\n",
    "print(doc_text)\n",
    "doc_activities = token_dataset.GetDocumentActivities(doc_name)\n",
    "\n",
    "print(\" activities and NER labels (per sentences) \".center(50, '*'))\n",
    "print(doc_activities)\n",
    "doc_sentence_ner_labels = relations_dataset.GetSentencesWithIdsAndNerTagLabels(doc_id)\n",
    "print(doc_sentence_ner_labels[:4])\n",
    "doc_relations = relations_dataset.GetRelations(doc_id)\n",
    "doc_flow_relations, doc_same_gateway_relations = doc_relations[FLOW], doc_relations[SAME_GATEWAY]\n",
    "\n",
    "print(\" same gateway relations \".center(50, '*'))\n",
    "for same_gateway_relation in doc_same_gateway_relations:\n",
    "    for key, value in same_gateway_relation.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2825e54a",
   "metadata": {},
   "source": [
    "### 1.2 Preprocess sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7564eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "A small company manufactures customized bicycles\n",
      "Whenever the sales department receives an order , a new process instance is created\n",
      "A member of the sales department can then reject or accept the order for a customized bike\n",
      "In the former case , the process instance is finished\n",
      "In the latter case , the storehouse and the engineering department are informed\n",
      "The storehouse immediately processes the part list of the order and checks the required quantity of each part\n",
      "If the part is available in-house , it is reserved\n",
      "If it is not available , it is back-ordered\n",
      "This procedure is repeated for each item on the part list\n",
      "In the meantime , the engineering department prepares everything for the assembling of the ordered bicycle\n",
      "If the storehouse has successfully reserved or back-ordered every item of the part list and the preparation activity has finished , the engineering department assembles the bicycle\n",
      "Afterwards , the sales department ships the bicycle to the customer and finishes the process instance\n"
     ]
    }
   ],
   "source": [
    "num_sentences = len(doc_activities) # activities is 2 dim list (one per sentence)\n",
    "print(num_sentences)\n",
    "doc_sentences_raw = [sentence.strip() for sentence in doc_text.split(\".\") if sentence.strip() != \"\"]\n",
    "for s in sentences_raw:\n",
    "    print(s)\n",
    "assert num_sentences == len(sentences_raw)  # check if number of extracted sentences == from dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cae193",
   "metadata": {},
   "source": [
    "### 1.3 Filter Tokens for Gateways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a174ac3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [('or', 9, 'B-XOR Gateway')], [], [], [], [('If', 0, 'B-XOR Gateway')], [('If', 0, 'B-XOR Gateway')], [], [('In', 0, 'B-AND Gateway'), ('the', 1, 'I-AND Gateway'), ('meantime', 2, 'I-AND Gateway')], [('If', 0, 'B-XOR Gateway')], []]\n"
     ]
    }
   ],
   "source": [
    "doc_gateway_tokens = [[token for token in s_list if \"Gateway\" in token[2]]\n",
    "                        for s_list in doc_sentence_ner_labels]\n",
    "# doc_gateway_tokens = list(itertools.chain(*doc_gateway_tokens)) # flattened\n",
    "print(doc_gateway_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2a97b3",
   "metadata": {},
   "source": [
    "### 1.X Filter Flow Relations? TODO\n",
    "see question doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1fefa",
   "metadata": {},
   "source": [
    "### 1.4 Key Word List\n",
    "#### A) take words from all existing gateways as gold list for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8193c95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR gold (15) ['either', 'for', 'for each patient for which', 'for the case', 'if', 'in case', 'in case of', 'in the case of', 'it can also happen that', 'or', 'otherwise', 'should', 'sometimes', 'under certain circumstances', 'whereas']\n",
      "AND gold (6) ['at the same time', 'in the meantime', 'meantime', 'two concurrent activities are triggered', 'whereas', 'while']\n"
     ]
    }
   ],
   "source": [
    "def get_gateway_key_words(dataset_gateway_list):\n",
    "    flattened = list(itertools.chain(*dataset_gateway_list))\n",
    "    phrases = [\" \".join(g).lower() for g in flattened]  # join phrases together if multiple words\n",
    "    unique = list(set(phrases))\n",
    "    unique.sort()\n",
    "    return unique\n",
    "\n",
    "xor_key_words_gold = get_gateway_key_words(token_dataset.GetXORGateways())\n",
    "and_key_words_gold = get_gateway_key_words(token_dataset.GetANDGateways())\n",
    "\n",
    "print(f\"XOR gold ({len(xor_key_words_gold)})\", xor_key_words_gold)\n",
    "print(f\"AND gold ({len(and_key_words_gold)})\", and_key_words_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4db3ff3",
   "metadata": {},
   "source": [
    "#### B) Curated List from Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64dc1873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR literature (14) ['either', 'if', 'if not', 'in case', 'in case of', 'only', 'only if', 'or', 'otherwise', 'till', 'unless', 'until', 'when', 'whether']\n",
      "AND literature (11) ['at the same time', 'concurrently', 'in addition to', 'in parallel', 'in parallel with this', 'in the meantime', 'meantime', 'meanwhile', 'simultaneously', 'whereas', 'while']\n"
     ]
    }
   ],
   "source": [
    "# Ferreira et al. 2017\n",
    "xor_key_words_literature = ['if', 'whether', 'if not', 'or', 'in case', 'in case of', 'otherwise', 'either', 'only', 'till', 'until', 'unless', 'when', 'only if']\n",
    "xor_key_words_literature.sort()\n",
    "and_key_words_literature = ['while', 'meanwhile', 'in parallel', 'concurrently', 'meantime', 'in the meantime', 'in parallel with this', 'in addition to', 'simultaneously', 'at the same time', 'whereas']\n",
    "and_key_words_literature.sort()\n",
    "print(f\"XOR literature ({len(xor_key_words_literature)})\", xor_key_words_literature)\n",
    "print(f\"AND literature ({len(and_key_words_literature)})\", and_key_words_literature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4e681",
   "metadata": {},
   "source": [
    "#### Select which set to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b1ae27a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR in use ['either', 'for', 'for each patient for which', 'for the case', 'if', 'in case', 'in case of', 'in the case of', 'it can also happen that', 'or', 'otherwise', 'should', 'sometimes', 'under certain circumstances', 'whereas', 'an order', 'it is']\n",
      "AND in use ['at the same time', 'in the meantime', 'meantime', 'two concurrent activities are triggered', 'whereas', 'while']\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    xor_key_words = xor_key_words_gold.copy()\n",
    "    and_key_words = and_key_words_gold.copy()\n",
    "else:\n",
    "    xor_key_words = xor_key_words_literature.copy()\n",
    "    and_key_words = and_key_words_literature.copy()\n",
    "    \n",
    "xor_key_words.append(\"an order\")\n",
    "xor_key_words.append(\"it is\")\n",
    "\n",
    "print(f\"XOR in use\", xor_key_words)\n",
    "print(f\"AND in use\", and_key_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70336395",
   "metadata": {},
   "source": [
    "## 2 Extract Gateways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d35a1b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small company manufactures customized bicycles\n",
      "Whenever the sales department receives an order , a new process instance is created\n",
      "A member of the sales department can then reject or accept the order for a customized bike\n",
      "In the former case , the process instance is finished\n",
      "In the latter case , the storehouse and the engineering department are informed\n",
      "The storehouse immediately processes the part list of the order and checks the required quantity of each part\n",
      "If the part is available in-house , it is reserved\n",
      "If it is not available , it is back-ordered\n",
      "This procedure is repeated for each item on the part list\n",
      "In the meantime , the engineering department prepares everything for the assembling of the ordered bicycle\n",
      "If the storehouse has successfully reserved or back-ordered every item of the part list and the preparation activity has finished , the engineering department assembles the bicycle\n",
      "Afterwards , the sales department ships the bicycle to the customer and finishes the process instance\n"
     ]
    }
   ],
   "source": [
    "for s in sentences_raw:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d9449229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- SENTENCE 0 -------------------\n",
      "A small company manufactures customized bicycles\n",
      "------------------- SENTENCE 1 -------------------\n",
      "Whenever the sales department receives an order , a new process instance is created\n",
      "------------------- SENTENCE 2 -------------------\n",
      "A member of the sales department can then reject or accept the order for a customized bike\n",
      "------------------- SENTENCE 3 -------------------\n",
      "In the former case , the process instance is finished\n",
      "------------------- SENTENCE 4 -------------------\n",
      "In the latter case , the storehouse and the engineering department are informed\n",
      "------------------- SENTENCE 5 -------------------\n",
      "The storehouse immediately processes the part list of the order and checks the required quantity of each part\n",
      "------------------- SENTENCE 6 -------------------\n",
      "If the part is available in-house , it is reserved\n",
      "------------------- SENTENCE 7 -------------------\n",
      "If it is not available , it is back-ordered\n",
      "------------------- SENTENCE 8 -------------------\n",
      "This procedure is repeated for each item on the part list\n",
      "------------------- SENTENCE 9 -------------------\n",
      "In the meantime , the engineering department prepares everything for the assembling of the ordered bicycle\n",
      "------------------ SENTENCE 10 -------------------\n",
      "If the storehouse has successfully reserved or back-ordered every item of the part list and the preparation activity has finished , the engineering department assembles the bicycle\n",
      "------------------ SENTENCE 11 -------------------\n",
      "Afterwards , the sales department ships the bicycle to the customer and finishes the process instance\n",
      "0 []\n",
      "1 [('an', 5, 'B-XOR Gateway'), ('order', 6, 'I-XOR Gateway')]\n",
      "2 [('or', 9, 'B-XOR Gateway'), ('for', 13, 'B-XOR Gateway')]\n",
      "3 []\n",
      "4 []\n",
      "5 []\n",
      "6 [('If', 0, 'B-XOR Gateway'), ('it', 7, 'B-XOR Gateway'), ('is', 8, 'I-XOR Gateway')]\n",
      "7 [('If', 0, 'B-XOR Gateway'), ('it', 1, 'B-XOR Gateway'), ('is', 2, 'I-XOR Gateway'), ('it', 6, 'B-XOR Gateway'), ('is', 7, 'I-XOR Gateway')]\n",
      "8 [('for', 4, 'B-XOR Gateway')]\n",
      "9 [('for', 9, 'B-XOR Gateway')]\n",
      "10 [('If', 0, 'B-XOR Gateway'), ('or', 6, 'B-XOR Gateway')]\n",
      "11 []\n"
     ]
    }
   ],
   "source": [
    "# result lists are two dimensional (list of tuples (word, tag) for each sentence)\n",
    "o_gateways = []\n",
    "\n",
    "for s_idx, sentence in enumerate(doc_sentences_raw):\n",
    "    print(f\" SENTENCE {s_idx} \".center(50, '-'))\n",
    "    print(sentences_raw[s_idx])\n",
    "    sentence_gateways = []\n",
    "    sentence_to_search = f\" {sentence.lower()} \"  # lowercase and wrap with spaces for search of key words\n",
    "    tokens = sentence.split(\" \")\n",
    "    tokens_lower = sentence.lower().split(\" \")\n",
    "    \n",
    "    # iterate over key phrases\n",
    "    for key_phrase in xor_key_words:\n",
    "        key_phrase_to_search = f\" {key_phrase} \"\n",
    "        \n",
    "        # if key phrase is in sentence, search index and extract\n",
    "        if key_phrase_to_search in sentence_to_search:\n",
    "\n",
    "            key_phrase_tokens = key_phrase.split(\" \")\n",
    "            # check key phrase for every token\n",
    "            for t_idx, token in enumerate(tokens_lower):\n",
    "                candidate = True\n",
    "                # iterate over key phrase tokens in case of multiple world phrase\n",
    "                for key_phrase_token_idx, key_phrase_token in enumerate(key_phrase_tokens):\n",
    "                    if not tokens_lower[t_idx + key_phrase_token_idx] == key_phrase_token:\n",
    "                        candidate = False\n",
    "                        break\n",
    "                if candidate:\n",
    "                    # add tokens to result\n",
    "                    for i, key_phrase_token in enumerate(key_phrase_tokens):\n",
    "                        prefix = \"B\" if i == 0 else \"I\"\n",
    "                        sentence_gateways.append((tokens[t_idx + i], t_idx + i, f\"{prefix}-{XOR_GATEWAY}\"))\n",
    "    \n",
    "    # TODO: unique sentence list (longer detected phrase wins) to avoid two hits for 'meantime' and 'in the meantime'\n",
    "    sentence_gateways.sort(key=lambda gateway_triple: gateway_triple[1])\n",
    "    o_gateways.append(sentence_gateways)\n",
    "\n",
    "for idx, sentence_gateways in enumerate(o_gateways):\n",
    "    print(idx, sentence_gateways)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430a2c1",
   "metadata": {},
   "source": [
    "## 3 Evaluate Extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
