{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3b2ed3",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d457efd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from petreader.RelationsExtraction import RelationsExtraction\n",
    "from petreader.TokenClassification import TokenClassification\n",
    "from petreader.labels import FLOW, SAME_GATEWAY, AND_GATEWAY, XOR_GATEWAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fea40a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\janek\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\patriziobellan--PET\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2 (last modified on Sun Jul  3 12:17:36 2022) since it couldn't be found locally at patriziobellan/PET., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset pet (C:\\Users\\janek\\.cache\\huggingface\\datasets\\patriziobellan___pet\\relations-extraction\\1.0.1\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " _______ _     _ _______       _____  _______ _______      ______  _______ _______ _______ _______ _______ _______\n",
      "    |    |_____| |______      |_____] |______    |         |     \\ |_____|    |    |_____| |______ |______    |   \n",
      "    |    |     | |______      |       |______    |         |_____/ |     |    |    |     | ______| |______    |   \n",
      "                                                                                                                  \n",
      "Discover more at: [https://pdi.fbk.eu/pet-dataset/]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.07157254219055176,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa6c84915444a8f92f3a5e567d1e3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from C:\\Users\\janek\\.cache\\huggingface\\modules\\datasets_modules\\datasets\\patriziobellan--PET\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2 (last modified on Sun Jul  3 12:17:36 2022) since it couldn't be found locally at patriziobellan/PET., or remotely on the Hugging Face Hub.\n",
      "Reusing dataset pet (C:\\Users\\janek\\.cache\\huggingface\\datasets\\patriziobellan___pet\\token-classification\\1.0.1\\38434e2af57af533c400c8975f37e43c08bb77739085a3c026a862b2efb668d2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " _______ _     _ _______       _____  _______ _______      ______  _______ _______ _______ _______ _______ _______\n",
      "    |    |_____| |______      |_____] |______    |         |     \\ |_____|    |    |_____| |______ |______    |   \n",
      "    |    |     | |______      |       |______    |         |_____/ |     |    |    |     | ______| |______    |   \n",
      "                                                                                                                  \n",
      "Discover more at: [https://pdi.fbk.eu/pet-dataset/]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04923295974731445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8dbb1614be4d7caa36a898827dcb08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relations_dataset = RelationsExtraction()\n",
    "token_dataset = TokenClassification()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3575c77e",
   "metadata": {},
   "source": [
    "## 1 Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4175e9",
   "metadata": {},
   "source": [
    "### 1.1 Read Example Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eef7b458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************  doc-1.1  ********************\n",
      "A small company manufactures customized bicycles . Whenever the sales department receives an order , a new process instance is created . A member of the sales department can then reject or accept the order for a customized bike . In the former case , the process instance is finished . In the latter case , the storehouse and the engineering department are informed . The storehouse immediately processes the part list of the order and checks the required quantity of each part . If the part is available in-house , it is reserved . If it is not available , it is back-ordered . This procedure is repeated for each item on the part list . In the meantime , the engineering department prepares everything for the assembling of the ordered bicycle . If the storehouse has successfully reserved or back-ordered every item of the part list and the preparation activity has finished , the engineering department assembles the bicycle . Afterwards , the sales department ships the bicycle to the customer and finishes the process instance .\n",
      "*** activities and NER labels (per sentences) ****\n",
      "[[], [['receives']], [['reject'], ['accept']], [], [['informed']], [['processes'], ['checks']], [['reserved']], [['back-ordered']], [], [['prepares']], [['assembles']], [['ships']]]\n",
      "[[('A', 0, 'O'), ('small', 1, 'O'), ('company', 2, 'O'), ('manufactures', 3, 'O'), ('customized', 4, 'O'), ('bicycles', 5, 'O'), ('.', 6, 'O')], [('Whenever', 0, 'O'), ('the', 1, 'B-Actor'), ('sales', 2, 'I-Actor'), ('department', 3, 'I-Actor'), ('receives', 4, 'B-Activity'), ('an', 5, 'B-Activity Data'), ('order', 6, 'I-Activity Data'), (',', 7, 'O'), ('a', 8, 'O'), ('new', 9, 'O'), ('process', 10, 'O'), ('instance', 11, 'O'), ('is', 12, 'O'), ('created', 13, 'O'), ('.', 14, 'O')], [('A', 0, 'O'), ('member', 1, 'O'), ('of', 2, 'O'), ('the', 3, 'O'), ('sales', 4, 'O'), ('department', 5, 'O'), ('can', 6, 'O'), ('then', 7, 'O'), ('reject', 8, 'B-Activity'), ('or', 9, 'B-XOR Gateway'), ('accept', 10, 'B-Activity'), ('the', 11, 'B-Activity Data'), ('order', 12, 'I-Activity Data'), ('for', 13, 'O'), ('a', 14, 'O'), ('customized', 15, 'O'), ('bike', 16, 'O'), ('.', 17, 'O')], [('In', 0, 'O'), ('the', 1, 'O'), ('former', 2, 'O'), ('case', 3, 'O'), (',', 4, 'O'), ('the', 5, 'O'), ('process', 6, 'O'), ('instance', 7, 'O'), ('is', 8, 'O'), ('finished', 9, 'O'), ('.', 10, 'O')]]\n",
      "************* same gateway relations *************\n",
      "source-head-sentence-ID: 6\n",
      "source-head-word-ID: 0\n",
      "source-entity-type: XOR Gateway\n",
      "source-entity: ['If']\n",
      "target-head-sentence-ID: 7\n",
      "target-head-word-ID: 0\n",
      "target-entity-type: XOR Gateway\n",
      "target-entity: ['If']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "doc_name = token_dataset.GetDocumentName(doc_id)\n",
    "print(f\"  {doc_name}  \".center(50, '*'))\n",
    "doc_text = relations_dataset.GetDocument(doc_id)\n",
    "print(doc_text)\n",
    "doc_activities = token_dataset.GetDocumentActivities(doc_name)\n",
    "\n",
    "print(\" activities and NER labels (per sentences) \".center(50, '*'))\n",
    "print(doc_activities)\n",
    "doc_sentence_ner_labels = relations_dataset.GetSentencesWithIdsAndNerTagLabels(doc_id)\n",
    "print(doc_sentence_ner_labels[:4])\n",
    "doc_relations = relations_dataset.GetRelations(doc_id)\n",
    "doc_flow_relations, doc_same_gateway_relations = doc_relations[FLOW], doc_relations[SAME_GATEWAY]\n",
    "\n",
    "print(\" same gateway relations \".center(50, '*'))\n",
    "for same_gateway_relation in doc_same_gateway_relations:\n",
    "    for key, value in same_gateway_relation.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb928452",
   "metadata": {},
   "source": [
    "### 1.2 Preprocess sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dff2cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "A small company manufactures customized bicycles\n",
      "Whenever the sales department receives an order , a new process instance is created\n",
      "A member of the sales department can then reject or accept the order for a customized bike\n",
      "In the former case , the process instance is finished\n",
      "In the latter case , the storehouse and the engineering department are informed\n",
      "The storehouse immediately processes the part list of the order and checks the required quantity of each part\n",
      "If the part is available in-house , it is reserved\n",
      "If it is not available , it is back-ordered\n",
      "This procedure is repeated for each item on the part list\n",
      "In the meantime , the engineering department prepares everything for the assembling of the ordered bicycle\n",
      "If the storehouse has successfully reserved or back-ordered every item of the part list and the preparation activity has finished , the engineering department assembles the bicycle\n",
      "Afterwards , the sales department ships the bicycle to the customer and finishes the process instance\n"
     ]
    }
   ],
   "source": [
    "num_sentences = len(doc_activities) # activities is 2 dim list (one per sentence)\n",
    "print(num_sentences)\n",
    "sentences_raw = [sentence.strip() for sentence in doc_text.split(\".\") if sentence.strip() != \"\"]\n",
    "for s in sentences_raw:\n",
    "    print(s)\n",
    "assert num_sentences == len(sentences_raw)  # check if number of extracted sentences == from dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeed366",
   "metadata": {},
   "source": [
    "### 1.3 Filter Tokens for Gateways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3024261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('or', 9, 'B-XOR Gateway'), ('If', 0, 'B-XOR Gateway'), ('If', 0, 'B-XOR Gateway'), ('In', 0, 'B-AND Gateway'), ('the', 1, 'I-AND Gateway'), ('meantime', 2, 'I-AND Gateway'), ('If', 0, 'B-XOR Gateway')]\n"
     ]
    }
   ],
   "source": [
    "doc_gateway_tokens = [[token for token in s_list if \"Gateway\" in token[2]]\n",
    "                        for s_list in doc_sentence_ner_labels]\n",
    "doc_gateway_tokens = list(itertools.chain(*doc_gateway_tokens)) # flattened\n",
    "print(doc_gateway_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710636a",
   "metadata": {},
   "source": [
    "### 1.X Filter Flow Relations? TODO\n",
    "see question doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf3836",
   "metadata": {},
   "source": [
    "### 1.4 Key Word List\n",
    "#### A) take words from all existing gateways as gold list for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6be61297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['either', 'for', 'for each patient for which', 'for the case', 'if', 'in case', 'in case of', 'in the case of', 'it can also happen that', 'or', 'otherwise', 'should', 'sometimes', 'under certain circumstances', 'whereas']\n",
      "['at the same time', 'in the meantime', 'meantime', 'two concurrent activities are triggered', 'whereas', 'while']\n"
     ]
    }
   ],
   "source": [
    "def get_gateway_key_words(dataset_gateway_list):\n",
    "    flattened = list(itertools.chain(*dataset_gateway_list))\n",
    "    phrases = [\" \".join(g).lower() for g in flattened]  # join phrases together if multiple words\n",
    "    unique = list(set(phrases))\n",
    "    unique.sort()\n",
    "    return unique\n",
    "\n",
    "xor_key_words_gold = get_gateway_key_words(token_dataset.GetXORGateways())\n",
    "and_key_words_gold = get_gateway_key_words(token_dataset.GetANDGateways())\n",
    "\n",
    "print(xor_key_words_gold)\n",
    "print(and_key_words_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f94df50",
   "metadata": {},
   "source": [
    "#### B) Curated List from Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e67ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
