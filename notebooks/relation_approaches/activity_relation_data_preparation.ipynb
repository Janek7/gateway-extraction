{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f495ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dir to sys path for import of modules\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "# find recursively the project root dir\n",
    "parent_dir = str(os.getcwdb())\n",
    "while not os.path.exists(os.path.join(parent_dir, \"README.md\")):\n",
    "    parent_dir = os.path.abspath(os.path.join(parent_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0157bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import itertools\n",
    "\n",
    "from petreader.labels import *\n",
    "\n",
    "from PetReader import pet_reader\n",
    "\n",
    "\n",
    "logger = logging.getLogger('Keywords Same Gateway Filtered Approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "133a037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = 'directly_following'\n",
    "EXCLUSIVE = 'exclusive'\n",
    "CONCURRENT = 'concurrent'\n",
    "\n",
    "SOURCE = 'source'\n",
    "TARGET = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "5052deb2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------ FLOW RELATIONS ------------------------------------------\n",
      "\n",
      "\n",
      "0 (1, 4, ['receives'], 'Activity') (2, 9, ['or'], 'XOR Gateway')\n",
      "18\n",
      "Gateway (2, 9, ['or'], 'XOR Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "\n",
      "\n",
      "1 (2, 9, ['or'], 'XOR Gateway') (2, 8, ['reject'], 'Activity')\n",
      "\n",
      "\n",
      "2 (2, 9, ['or'], 'XOR Gateway') (2, 10, ['accept'], 'Activity')\n",
      "\n",
      "\n",
      "3 (2, 10, ['accept'], 'Activity') (4, 12, ['informed'], 'Activity')\n",
      "\n",
      "\n",
      "4 (4, 12, ['informed'], 'Activity') (9, 0, ['In', 'the', 'meantime'], 'AND Gateway')\n",
      "14\n",
      "DEBUG (9, 7, ['prepares'], 'Activity')\n",
      "DEBUG (5, 3, ['processes'], 'Activity')\n",
      "DEBUG (10, 0, ['If'], 'XOR Gateway')\n",
      "DEBUG (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification')\n",
      "DEBUG (10, 24, ['assembles'], 'Activity')\n",
      "DEBUG (11, 5, ['ships'], 'Activity')\n",
      "DEBUG (5, 11, ['checks'], 'Activity')\n",
      "DEBUG (6, 0, ['If'], 'XOR Gateway')\n",
      "DEBUG (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification')\n",
      "DEBUG (6, 9, ['reserved'], 'Activity')\n",
      "DEBUG (10, 0, ['If'], 'XOR Gateway')\n",
      "Gateway (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "\n",
      "\n",
      "5 (5, 3, ['processes'], 'Activity') (5, 11, ['checks'], 'Activity')\n",
      "\n",
      "\n",
      "6 (5, 11, ['checks'], 'Activity') (6, 0, ['If'], 'XOR Gateway')\n",
      "12\n",
      "Gateway (6, 0, ['If'], 'XOR Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "same gateway (7, 0, ['If'], 'XOR Gateway')\n",
      "[]\n",
      "\n",
      "\n",
      "7 (6, 0, ['If'], 'XOR Gateway') (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification')\n",
      "\n",
      "\n",
      "8 (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification') (6, 9, ['reserved'], 'Activity')\n",
      "\n",
      "\n",
      "9 (6, 9, ['reserved'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "3\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "\n",
      "\n",
      "10 (7, 0, ['If'], 'XOR Gateway') (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification')\n",
      "\n",
      "\n",
      "11 (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification') (7, 8, ['back-ordered'], 'Activity')\n",
      "\n",
      "\n",
      "12 (7, 8, ['back-ordered'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "3\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "\n",
      "\n",
      "13 (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') (9, 7, ['prepares'], 'Activity')\n",
      "\n",
      "\n",
      "14 (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') (5, 3, ['processes'], 'Activity')\n",
      "\n",
      "\n",
      "15 (9, 7, ['prepares'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "3\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "\n",
      "\n",
      "16 (10, 0, ['If'], 'XOR Gateway') (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification')\n",
      "\n",
      "\n",
      "17 (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification') (10, 24, ['assembles'], 'Activity')\n",
      "\n",
      "\n",
      "18 (10, 24, ['assembles'], 'Activity') (11, 5, ['ships'], 'Activity')\n",
      "--------------------------------------------- RESULTS ----------------------------------------------\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (2, 8, ['reject'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (2, 10, ['accept'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (2, 10, ['accept'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'directly_following', 'g -> sg -> cond -> a')\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (7, 8, ['back-ordered'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'directly_following', 'normal df')\n",
      "relations: 19\n"
     ]
    }
   ],
   "source": [
    "def transform_relations(relations):\n",
    "    results = [{SOURCE: (r[SOURCE_SENTENCE_ID], r[SOURCE_HEAD_TOKEN_ID], r[SOURCE_ENTITY], r[SOURCE_ENTITY_TYPE]),\n",
    "                TARGET: (r[TARGET_SENTENCE_ID], r[TARGET_HEAD_TOKEN_ID], r[TARGET_ENTITY], r[TARGET_ENTITY_TYPE])}\n",
    "               for r in relations]\n",
    "    return results\n",
    "\n",
    "def get_linked_activities(gateway, flow_relations):\n",
    "    return [r[TARGET] for r in flow_relations if r[SOURCE] == gateway and r[TARGET][3] == ACTIVITY]\n",
    "\n",
    "def get_linked_activities_via_condition(gateway, flow_relations):\n",
    "    return [[r2[TARGET] for r2 in flow_relations if r2[SOURCE] == r[TARGET] and r2[TARGET][3] == ACTIVITY][0]\n",
    "            for r in flow_relations if r[SOURCE] == gateway and r[TARGET][3] == CONDITION_SPECIFICATION]\n",
    "\n",
    "def get_sg_gateways(gateway, sg_relations):\n",
    "    \"\"\"\n",
    "    search for gateways that are related to the given gateway via a same gateway relation\n",
    "    search is conducted recursively to support multi branch gateways (>2 branches)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for sg in sg_relations:\n",
    "        if sg[SOURCE] == gateway:\n",
    "            results.append(sg[TARGET])\n",
    "            recursive_gateways = get_sg_gateways_recursive(sg[TARGET], sg_relations)\n",
    "            if recursive_gateways:\n",
    "                results.extend(recursive_gateways)\n",
    "    return results\n",
    "\n",
    "def get_following_flows_by_text_structure(element, flow_relations):\n",
    "    return [f for f in flow_relations if f[SOURCE][0] >= element[0] \n",
    "                                      or (f[SOURCE][0] == element[0] and f[SOURCE][1] >= element[1])]\n",
    "\n",
    "def find_next_merge_activity(element, flow_relations):\n",
    "    \"\"\"\n",
    "    find next activity that has multiple incoming flows (i.e. merge point) \n",
    "    \"\"\"\n",
    "    relevant_flows = get_following_flows_by_text_structure(element, flow_relations)\n",
    "    \n",
    "    # add flows ongoing from directly linked activities because structure in text can be different then process structure (e.g. doc-1.1 parallel gateway)\n",
    "    directy_linked_activities = [f[TARGET] for f in flow_relations if f[SOURCE] == element]\n",
    "    for a in directy_linked_activities:\n",
    "        relevant_flows.extend(get_following_flows_by_text_structure(a, flow_relations))\n",
    "    # filter for unique flows\n",
    "    relevant_flows_u = []\n",
    "    for f in relevant_flows:\n",
    "        if f not in relevant_flows_u:\n",
    "            relevant_flows_u.append(f)\n",
    "    relevant_flows = relevant_flows_u\n",
    "    \n",
    "    next_targets = []\n",
    "    print(len(relevant_flows))\n",
    "    for f in relevant_flows:\n",
    "        if element[3] == AND_GATEWAY:\n",
    "            print(\"DEBUG\", f[TARGET])\n",
    "        if f[TARGET] in next_targets:\n",
    "            return f[TARGET]\n",
    "        else:\n",
    "            next_targets.append(f[TARGET])\n",
    "    # raise Exception(f\"no merge point found for {element}\")  # TODO: change to GatewayExtractionException\n",
    "    print(\"WARNING: no merge point found\")\n",
    "    return None\n",
    "\n",
    "def get_activities_until_merge_point(element, next_merge, flow_relations):\n",
    "    \"\"\"\n",
    "    return all activities between given element and next given merge point based on flow relations/connections\n",
    "    \"\"\"\n",
    "    relevant_flows = get_following_flows_by_text_structure(element, flow_relations)\n",
    "    activities_between = [element]\n",
    "    for f in relevant_flows:\n",
    "        if f[SOURCE] == activities_between[-1] \\\n",
    "            and (f[TARGET][0] < next_merge[0] or (f[TARGET][0] == next_merge[0] and f[TARGET][1] < next_merge[1])):\n",
    "            activities_between.append(f[TARGET])\n",
    "    return activities_between[1:]\n",
    "\n",
    "\n",
    "def data_generation(doc_names, whole_branch_pairs=True):\n",
    "    \n",
    "    # data format ? -> (doc_name, (a1), (a2), type, comment)\n",
    "    # split/merge points are represented as directly follow relations \n",
    "    relations = []\n",
    "    \n",
    "    for i, doc_name in enumerate(pet_reader.document_names):\n",
    "        \n",
    "#         if doc_name == 'doc-1.1':\n",
    "#             continue\n",
    "            \n",
    "        if doc_names and doc_name not in doc_names:\n",
    "            continue\n",
    "            \n",
    "        # 1) Search for exlusive relations using XOR gateways\n",
    "        doc_relations = pet_reader.relations_dataset.GetRelations(pet_reader.get_document_number(doc_name))\n",
    "        flow_relations = transform_relations(doc_relations[FLOW])\n",
    "        same_gateway_relations = transform_relations(doc_relations[SAME_GATEWAY])\n",
    "        \n",
    "        print(\" FLOW RELATIONS \".center(100, '-'))\n",
    "        \n",
    "        for i, f in enumerate(flow_relations):\n",
    "            print(\"\\n\")\n",
    "            print(i, f[SOURCE], f[TARGET])\n",
    "            \n",
    "            # a) DIRECTLY FOLLOWING RELATIONS\n",
    "            if f[SOURCE][3] == f[TARGET][3] == ACTIVITY:\n",
    "                relations.append((doc_name, f[SOURCE], f[TARGET], DF, \"normal df\"))\n",
    "                \n",
    "            # b) GATEWAY RELATIONS\n",
    "            if f[SOURCE][3] == ACTIVITY and f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY]:\n",
    "                gateway = f[TARGET]\n",
    "                gateway_merge_point = find_next_merge_activity(gateway, flow_relations)\n",
    "                print(f\"Gateway {gateway} - merge point: {gateway_merge_point}\")\n",
    "                \n",
    "                # extract activities to which the gateway refers\n",
    "                \n",
    "                \n",
    "                # - 1) in case of direct activity link without conditon and same gateway\n",
    "                # cases: exlusive 'or' gateways || parallel gateways\n",
    "                directly_linked_activities = get_linked_activities(gateway, flow_relations)\n",
    "                # add relations of activities before to (directly linked) gateway activities via DF\n",
    "                for a in directly_linked_activities:\n",
    "                    relations.append((doc_name, f[SOURCE], a, DF, \"g -> a\")) \n",
    "                # add exclusive/concurrent relations between (multiple) activities of branches\n",
    "                # first create list of activities for each branch\n",
    "                activity_branches = [[a] + (get_activities_until_merge_point(a, gateway_merge_point, flow_relations) if whole_branch_pairs and gateway_merge_point else [])\n",
    "                                     for a in directly_linked_activities]\n",
    "                # second create connections between all activities of each pair of branches \n",
    "                for branchA, branchB in itertools.combinations(activity_branches, 2):\n",
    "                    for a1, a2 in itertools.product(*[branchA, branchB]):\n",
    "                        if a1[3] == ACTIVITY and a2[3] == ACTIVITY:  # omit gateways or condition specs\n",
    "                            relations.append((doc_name, a1, a2, EXCLUSIVE if gateway[3] == XOR_GATEWAY else CONCURRENT, \"branches\"))\n",
    "                \n",
    "                \n",
    "                \n",
    "                # - 2) in case of indirect link via condition specification and same gateway relations\n",
    "                gateway_branches_activities_directly_linked = []\n",
    "                condition_spec_linked = get_linked_activities_via_condition(gateway, flow_relations)\n",
    "                for a in condition_spec_linked:\n",
    "                    if a:\n",
    "                        relations.append((doc_name, f[SOURCE], a, DF, \"g -> cond -> a\")) \n",
    "                        gateway_branches_activities_directly_linked.append(a)\n",
    "                    else:\n",
    "                        print(\"&&&&&&&& ERROR\")\n",
    "                \n",
    "                # detect same gateways and repeat procedure for them\n",
    "                sg_gateways = get_sg_gateways(gateway, same_gateway_relations)\n",
    "                for sg_gateway in sg_gateways:\n",
    "                    print(\"same gateway\", sg_gateway)\n",
    "                    # directly linked\n",
    "                    sg_linked_activities = get_linked_activities(sg_gateway, flow_relations)\n",
    "                    print(sg_linked_activities)\n",
    "                    for a in sg_linked_activities:\n",
    "                        relations.append((doc_name, f[SOURCE], a, DF, \"g -> sg -> a\"))\n",
    "                        gateway_branches_activities_directly_linked.append(a)\n",
    "                    # linked via condition\n",
    "                    sg_gateway_condition_spec_linked = get_linked_activities_via_condition(sg_gateway, flow_relations)\n",
    "                    for a in sg_gateway_condition_spec_linked:\n",
    "                        relations.append((doc_name, f[SOURCE], a, DF, \"g -> sg -> cond -> a\"))\n",
    "                        gateway_branches_activities_directly_linked.append(a)\n",
    "                        \n",
    "                # add exclusive/concurrent relations between (multiple) activities of branches\n",
    "                # first create list of activities for each branch\n",
    "                activity_branches = [[a] + (get_activities_until_merge_point(a, gateway_merge_point, flow_relations) if whole_branch_pairs and gateway_merge_point else [])\n",
    "                                     for a in gateway_branches_activities_directly_linked]\n",
    "                # second create connections between all activities of each pair of branches \n",
    "                for branchA, branchB in itertools.combinations(activity_branches, 2):\n",
    "                    for a1, a2 in itertools.product(*[branchA, branchB]):\n",
    "                        if a1[3] == ACTIVITY and a2[3] == ACTIVITY:  # omit gateways or condition specs\n",
    "                            relations.append((doc_name, a1, a2, EXCLUSIVE if gateway[3] == XOR_GATEWAY else CONCURRENT, \"branches\"))\n",
    "                \n",
    "                # TODO: cases where gateway is at the start of the document\n",
    "                # TODO: one branch gateways\n",
    "\n",
    "    # filter duplicates & sort\n",
    "    relations_final = []\n",
    "    for r in relations:\n",
    "        if r not in relations_final:\n",
    "            relations_final.append(r)\n",
    "    relations_final.sort(key=lambda r: (r[1][0], r[1][1]))\n",
    "\n",
    "    return relations_final\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "activity_relations = data_generation(['doc-1.1'], whole_branch_pairs=True)\n",
    "print(\" RESULTS \".center(100, '-'))\n",
    "for relation in activity_relations:\n",
    "    print(relation)\n",
    "print(\"relations:\", len(activity_relations))\n",
    "# check again: doc-1.1; doc-1.2; doc-6.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
