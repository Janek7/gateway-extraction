{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e74d7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dir to sys path for import of modules\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "# find recursively the project root dir\n",
    "parent_dir = str(os.getcwdb())\n",
    "while not os.path.exists(os.path.join(parent_dir, \"README.md\")):\n",
    "    parent_dir = os.path.abspath(os.path.join(parent_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "deb47b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import itertools\n",
    "\n",
    "from petreader.labels import *\n",
    "\n",
    "from PetReader import pet_reader\n",
    "\n",
    "\n",
    "logger = logging.getLogger('Keywords Same Gateway Filtered Approach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d198faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = 'directly_following'\n",
    "EXCLUSIVE = 'exclusive'\n",
    "CONCURRENT = 'concurrent'\n",
    "\n",
    "SOURCE = 'source'\n",
    "TARGET = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "df2af4a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------ FLOW RELATIONS ------------------------------------------\n",
      "\n",
      "\n",
      "0 (1, 4, ['receives'], 'Activity') (2, 9, ['or'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (2, 9, ['or'], 'XOR Gateway') - merge point: None\n",
      "-- Activity Branches\n",
      "0 [(2, 8, ['reject'], 'Activity')]\n",
      "1 [(2, 10, ['accept'], 'Activity'), (4, 12, ['informed'], 'Activity'), (9, 0, ['In', 'the', 'meantime'], 'AND Gateway'), (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), (9, 0, ['In', 'the', 'meantime'], 'AND Gateway'), (5, 11, ['checks'], 'Activity'), (6, 0, ['If'], 'XOR Gateway'), (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "1 (2, 9, ['or'], 'XOR Gateway') (2, 8, ['reject'], 'Activity')\n",
      "\n",
      "\n",
      "2 (2, 9, ['or'], 'XOR Gateway') (2, 10, ['accept'], 'Activity')\n",
      "\n",
      "\n",
      "3 (2, 10, ['accept'], 'Activity') (4, 12, ['informed'], 'Activity')\n",
      "\n",
      "\n",
      "4 (4, 12, ['informed'], 'Activity') (9, 0, ['In', 'the', 'meantime'], 'AND Gateway')\n",
      "Gateway (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "-- Activity Branches\n",
      "0 [(9, 7, ['prepares'], 'Activity')]\n",
      "1 [(5, 3, ['processes'], 'Activity'), (5, 11, ['checks'], 'Activity'), (6, 0, ['If'], 'XOR Gateway'), (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity'), (6, 0, ['If'], 'XOR Gateway'), (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity')]\n",
      "\n",
      "\n",
      "5 (5, 3, ['processes'], 'Activity') (5, 11, ['checks'], 'Activity')\n",
      "\n",
      "\n",
      "6 (5, 11, ['checks'], 'Activity') (6, 0, ['If'], 'XOR Gateway')\n",
      "Gateway (6, 0, ['If'], 'XOR Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "-- Activity Branches\n",
      "0 [(6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity')]\n",
      "same gateway (7, 0, ['If'], 'XOR Gateway') linked entities: [(7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification')]\n",
      "-- Activity Branches\n",
      "0 [(6, 9, ['reserved'], 'Activity')]\n",
      "1 [(7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification'), (7, 8, ['back-ordered'], 'Activity')]\n",
      "2 [(7, 8, ['back-ordered'], 'Activity')]\n",
      "\n",
      "\n",
      "7 (6, 0, ['If'], 'XOR Gateway') (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification')\n",
      "\n",
      "\n",
      "8 (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification') (6, 9, ['reserved'], 'Activity')\n",
      "\n",
      "\n",
      "9 (6, 9, ['reserved'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "-- Activity Branches\n",
      "0 [(10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "-- Activity Branches\n",
      "0 [(10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "10 (7, 0, ['If'], 'XOR Gateway') (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification')\n",
      "\n",
      "\n",
      "11 (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification') (7, 8, ['back-ordered'], 'Activity')\n",
      "\n",
      "\n",
      "12 (7, 8, ['back-ordered'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "-- Activity Branches\n",
      "0 [(10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "-- Activity Branches\n",
      "0 [(10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "13 (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') (9, 7, ['prepares'], 'Activity')\n",
      "\n",
      "\n",
      "14 (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') (5, 3, ['processes'], 'Activity')\n",
      "\n",
      "\n",
      "15 (9, 7, ['prepares'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "-- Activity Branches\n",
      "0 [(10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "-- Activity Branches\n",
      "0 [(10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "16 (10, 0, ['If'], 'XOR Gateway') (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification')\n",
      "\n",
      "\n",
      "17 (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification') (10, 24, ['assembles'], 'Activity')\n",
      "\n",
      "\n",
      "18 (10, 24, ['assembles'], 'Activity') (11, 5, ['ships'], 'Activity')\n",
      "--------------------------------------------- RESULTS ----------------------------------------------\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (2, 8, ['reject'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (2, 10, ['accept'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (2, 10, ['accept'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'directly_following', 'g -> sg -> cond -> a')\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (7, 8, ['back-ordered'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (7, 8, ['back-ordered'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'directly_following', 'normal df')\n",
      "relations: 25\n"
     ]
    }
   ],
   "source": [
    "def transform_relations(relations):\n",
    "    results = [{SOURCE: (r[SOURCE_SENTENCE_ID], r[SOURCE_HEAD_TOKEN_ID], r[SOURCE_ENTITY], r[SOURCE_ENTITY_TYPE]),\n",
    "                TARGET: (r[TARGET_SENTENCE_ID], r[TARGET_HEAD_TOKEN_ID], r[TARGET_ENTITY], r[TARGET_ENTITY_TYPE])}\n",
    "               for r in relations]\n",
    "    return results\n",
    "\n",
    "def unique_ordered_flows(flows):\n",
    "    flows_u = []\n",
    "    for f in flows:\n",
    "        if f not in flows_u:\n",
    "            flows_u.append(f)\n",
    "    flows_u.sort(key=lambda f: (f[SOURCE][0], f[SOURCE][1]))\n",
    "    return flows_u\n",
    "    \n",
    "\n",
    "def get_linked_entities(gateway, flow_relations):\n",
    "    return [r[TARGET] for r in flow_relations if r[SOURCE] == gateway]\n",
    "\n",
    "def get_linked_entities_via_condition(gateway, flow_relations):\n",
    "    return [[r2[TARGET] for r2 in flow_relations if r2[SOURCE] == r[TARGET]][0]\n",
    "            for r in flow_relations if r[SOURCE] == gateway and r[TARGET][3] == CONDITION_SPECIFICATION]\n",
    "\n",
    "def get_sg_gateways(gateway, sg_relations):\n",
    "    \"\"\"\n",
    "    search for gateways that are related to the given gateway via a same gateway relation\n",
    "    search is conducted recursively to support multi branch gateways (>2 branches)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for sg in sg_relations:\n",
    "        if sg[SOURCE] == gateway:\n",
    "            results.append(sg[TARGET])\n",
    "            recursive_gateways = get_sg_gateways_recursive(sg[TARGET], sg_relations)\n",
    "            if recursive_gateways:\n",
    "                results.extend(recursive_gateways)\n",
    "    return results\n",
    "\n",
    "def get_following_flows_by_text_structure(element, flow_relations):\n",
    "    return [f for f in flow_relations if f[SOURCE][0] > element[0] \n",
    "                                      or (f[SOURCE][0] == element[0] and f[SOURCE][1] >= element[1])]\n",
    "\n",
    "def get_following_flows(element, flow_relations):\n",
    "    # start with flows following by text structure\n",
    "    following_flows = get_following_flows_by_text_structure(element, flow_relations)\n",
    "    \n",
    "    # check for other links to the element before the element itself\n",
    "    for f in flow_relations:\n",
    "        if f[SOURCE] == element:\n",
    "            following_flows.extend(get_following_flows_by_text_structure(f[SOURCE], flow_relations))\n",
    "    \n",
    "    return unique_ordered_flows(following_flows)\n",
    "\n",
    "def get_previous_flows_by_text_structure(element, flow_relations):\n",
    "    return [f for f in flow_relations if f[SOURCE][0] < element[0] \n",
    "                                      or (f[SOURCE][0] == element[0] and f[SOURCE][1] <= element[1])]\n",
    "\n",
    "def get_number_incoming_flows(element, flow_relations):\n",
    "    return len([f for f in flow_relations if f[TARGET] == element])\n",
    "\n",
    "def find_next_merge_point(element, flow_relations):\n",
    "    \"\"\"\n",
    "    find next activity that has multiple incoming flows (i.e. merge point) \n",
    "    \"\"\"\n",
    "    relevant_flows = get_following_flows_by_text_structure(element, flow_relations)\n",
    "    \n",
    "    # add flows ongoing from directly linked activities because structure in text can be different then process structure (e.g. doc-1.1 parallel gateway)\n",
    "    directy_linked_entities = get_linked_entities(element, flow_relations)\n",
    "    for e in directy_linked_entities:\n",
    "        relevant_flows.extend(get_following_flows_by_text_structure(e, flow_relations))\n",
    "    \n",
    "    # filter for unique flows & order\n",
    "    relevant_flows = unique_ordered_flows(relevant_flows)\n",
    "    \n",
    "    next_targets = []\n",
    "    unclosed_gateways = 1\n",
    "    for f in relevant_flows:\n",
    "        # another gateway opened that has to be closed first\n",
    "        # check for incoming flows == 1 because with > 1 gateway is merge point as well\n",
    "        if f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY] and get_number_incoming_flows(f[TARGET], flow_relations) == 1:\n",
    "            unclosed_gateways += 1\n",
    "        if f[TARGET] in next_targets:\n",
    "            # one closing found\n",
    "            unclosed_gateways -= 1\n",
    "            # check if all opened gateways are closed\n",
    "            if unclosed_gateways == 0:\n",
    "                return f[TARGET]\n",
    "        else:\n",
    "            next_targets.append(f[TARGET])\n",
    "    print(\"WARNING: no merge point found\")\n",
    "    return None\n",
    "\n",
    "def get_activities_until_merge_point(element, next_merge, flow_relations):\n",
    "    \"\"\"\n",
    "    return all activities between given element and next given merge point based on flow relations/connections\n",
    "    if merge point is None, return all activities until the end\n",
    "    \"\"\"\n",
    "    relevant_flows = get_following_flows(element, flow_relations)\n",
    "    activities_between = [element]\n",
    "\n",
    "    # iterate twice because semantical structure does not always follows textual structure -> in first run not all are captured\n",
    "    # duplicates will be created, but filtered after again\n",
    "    def dummy():\n",
    "        for f in flow_relations:\n",
    "            # if source of new flow is in already recorded elements and (no merge exist or target is before merge)\n",
    "            if f[SOURCE] in activities_between \\\n",
    "                and (not next_merge or \\\n",
    "                     (f[TARGET][0] < next_merge[0] or (f[TARGET][0] == next_merge[0] and f[TARGET][1] < next_merge[1]))):\n",
    "                activities_between.append(f[TARGET])\n",
    "    dummy()\n",
    "    # remove start element\n",
    "    activities_between = activities_between[1:]\n",
    "    dummy()\n",
    "    \n",
    "    # make unique again\n",
    "    activities_between_u = []\n",
    "    for a in activities_between:\n",
    "        if a not in activities_between_u:\n",
    "            activities_between_u.append(a)\n",
    "\n",
    "    return activities_between\n",
    "\n",
    "def get_last_activities(flow, flow_relations):\n",
    "    \"\"\"\n",
    "    search for last (transitively) linked activities (recursively) before current flow\n",
    "    :param flow: flow to start reversed search for\n",
    "    :param flow_relations: set of flows\n",
    "    :return: list of transitive connected activities\n",
    "    \"\"\"\n",
    "    last_activities = []\n",
    "    relevant_flows = get_previous_flows_by_text_structure(flow[SOURCE], flow_relations)\n",
    "    last_element = flow[SOURCE]\n",
    "    \n",
    "    # search from this flow to search reversed for last activities    \n",
    "    while not last_activities:\n",
    "        source_flows = [f for f in relevant_flows if f[TARGET] == last_element]\n",
    "        temp_new_activities = []\n",
    "        for source_flow in source_flows:\n",
    "            # a) base case -> activity found\n",
    "            if source_flow[SOURCE][3] == ACTIVITY:\n",
    "                temp_new_activities.append(source_flow[SOURCE])\n",
    "            # b) recursive case -> continue search from flow before\n",
    "            else:\n",
    "                temp_new_activities.extend(get_last_activities(source_flow, relevant_flows))\n",
    "        last_activities.extend(temp_new_activities)\n",
    "        \n",
    "    return last_activities\n",
    "\n",
    "\n",
    "def data_generation(doc_names, whole_branch_pairs=True):\n",
    "    \n",
    "    # data format -> (doc_name, (a1), (a2), type, comment)\n",
    "    # split/merge points are represented as directly follow relations \n",
    "    relations = []\n",
    "    \n",
    "    for i, doc_name in enumerate(pet_reader.document_names):\n",
    "        \n",
    "#         if doc_name == 'doc-1.1':\n",
    "#             continue\n",
    "            \n",
    "        if doc_names and doc_name not in doc_names:\n",
    "            continue\n",
    "            \n",
    "        # 1) Search for relations using gateways\n",
    "        doc_relations = pet_reader.relations_dataset.GetRelations(pet_reader.get_document_number(doc_name))\n",
    "        flow_relations = transform_relations(doc_relations[FLOW])\n",
    "        same_gateway_relations = transform_relations(doc_relations[SAME_GATEWAY])\n",
    "        \n",
    "        print(\" FLOW RELATIONS \".center(100, '-'))\n",
    "        \n",
    "        for i, f in enumerate(flow_relations):\n",
    "            print(\"\\n\")\n",
    "            print(i, f[SOURCE], f[TARGET])\n",
    "            \n",
    "            # a) DIRECTLY FOLLOWING RELATIONS\n",
    "            if f[SOURCE][3] == f[TARGET][3] == ACTIVITY:\n",
    "                relations.append((doc_name, f[SOURCE], f[TARGET], DF, \"normal df\"))\n",
    "                \n",
    "            # b) RELATIONS INVOLVING GATEWAYS\n",
    "            if f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY]:\n",
    "                \n",
    "                # extract source activity of current flow for linking pairing with following activities of gateway (f[TARGET]) \n",
    "                if f[SOURCE][3] == ACTIVITY:\n",
    "                    source_activities = [f[SOURCE]]\n",
    "                # if gateways are nested/referring each other -> lookup previous last normal activity recursively\n",
    "                elif f[SOURCE][3] in [CONDITION_SPECIFICATION, XOR_GATEWAY, AND_GATEWAY]:\n",
    "                    source_activities = get_last_activities(f, flow_relations)\n",
    "                    print(f\"Nested gateway - transitive last activities: {source_activities}\")\n",
    "                else:\n",
    "                    raise Exception(\"Other flow combination!\")\n",
    "                    \n",
    "                \n",
    "                gateway = f[TARGET]\n",
    "                gateway_merge_point = find_next_merge_point(gateway, flow_relations)\n",
    "                print(f\"Gateway {gateway} - merge point: {gateway_merge_point}\")\n",
    "                \n",
    "                # create flows from possible multiple incomes to current gateway (only in case of directly nested gateways)\n",
    "                # to possible multiple outcomes (normal for gateways)\n",
    "                \n",
    "                # extract activities to which the gateway refers\n",
    "\n",
    "                # - 1) in case of direct entity (activity or further gateway) link without conditon and same gateway\n",
    "                # cases: exlusive 'or' gateways || parallel gateways\n",
    "                directly_linked_entities = get_linked_entities(gateway, flow_relations)\n",
    "                # add relations of activities before to (directly linked) gateway activities via DF\n",
    "                for e in directly_linked_entities:\n",
    "                    if e[3] == ACTIVITY:\n",
    "                        for source_activity in source_activities:\n",
    "                            relations.append((doc_name, source_activity, e, DF, \"g -> a\"))\n",
    "                # add exclusive/concurrent relations between (multiple) activities of branches\n",
    "                # first create list of activities for each branch\n",
    "                activity_branches = [[e] + (get_activities_until_merge_point(e, gateway_merge_point, flow_relations) if whole_branch_pairs else [])\n",
    "                                     for e in directly_linked_entities]\n",
    "\n",
    "                # second create connections between all activities of each pair of branches \n",
    "                if activity_branches:\n",
    "                    print(\"-- Activity Branches\")\n",
    "                    for i, b in enumerate(activity_branches):\n",
    "                        print(i, b)\n",
    "                    \n",
    "                    for branchA, branchB in itertools.combinations(activity_branches, 2):\n",
    "                        for e1, e2 in itertools.product(*[branchA, branchB]):\n",
    "                            if e1[3] == ACTIVITY and e2[3] == ACTIVITY:  # omit gateways or condition specs\n",
    "                                relations.append((doc_name, e1, e2, EXCLUSIVE if gateway[3] == XOR_GATEWAY else CONCURRENT, \"branches\"))\n",
    "\n",
    "\n",
    "\n",
    "                # - 2) in case of indirect link via condition specification and same gateway relations\n",
    "                gateway_branches_entities_directly_linked = []\n",
    "                condition_spec_linked = get_linked_entities_via_condition(gateway, flow_relations)\n",
    "                for e in condition_spec_linked:\n",
    "                    if e:\n",
    "                        if e[3] == ACTIVITY:\n",
    "                            for source_activity in source_activities:\n",
    "                                relations.append((doc_name, source_activity, e, DF, \"g -> cond -> a\")) \n",
    "                            gateway_branches_entities_directly_linked.append(e)\n",
    "                        # not activity is linked, but other (gateway, cond) from which following activities will be included as well\n",
    "                        else:\n",
    "                            gateway_branches_entities_directly_linked.append(e)\n",
    "                    else:\n",
    "                        print(\"&&&&&&&& ERROR\")\n",
    "\n",
    "                # detect same gateways and repeat procedure for them\n",
    "                sg_gateways = get_sg_gateways(gateway, same_gateway_relations)\n",
    "                for sg_gateway in sg_gateways:\n",
    "                    # directly linked\n",
    "                    sg_linked_entities = get_linked_entities(sg_gateway, flow_relations)\n",
    "                    print(\"same gateway\", sg_gateway, \"linked entities:\", sg_linked_entities)\n",
    "                    for e in sg_linked_entities:\n",
    "                        if e[3] == ACTIVITY:\n",
    "                            for source_activity in source_activities:\n",
    "                                relations.append((doc_name, source_activity, e, DF, \"g -> sg -> a\"))\n",
    "                            gateway_branches_entities_directly_linked.append(e)\n",
    "                        # not activity is linked, but other (gateway, cond) from which following activities will be included as well\n",
    "                        else:\n",
    "                            gateway_branches_entities_directly_linked.append(e)\n",
    "                    # linked via condition\n",
    "                    sg_gateway_condition_spec_linked = get_linked_entities_via_condition(sg_gateway, flow_relations)\n",
    "                    for e in sg_gateway_condition_spec_linked:\n",
    "                        if e[3] == ACTIVITY:\n",
    "                            for source_activity in source_activities:\n",
    "                                relations.append((doc_name, source_activity, e, DF, \"g -> sg -> cond -> a\"))\n",
    "                            gateway_branches_entities_directly_linked.append(e)\n",
    "                        # not activity is linked, but other (gateway, cond) from which following activities will be included as well\n",
    "                        else:\n",
    "                            gateway_branches_entities_directly_linked.append(e)\n",
    "\n",
    "                # add exclusive/concurrent relations between (multiple) activities of branches\n",
    "                # first create list of activities for each branch\n",
    "                activity_branches = [[e] + (get_activities_until_merge_point(e, gateway_merge_point, flow_relations) if whole_branch_pairs else [])\n",
    "                                     for e in gateway_branches_entities_directly_linked]\n",
    "                if activity_branches:\n",
    "                    print(\"-- Activity Branches\")\n",
    "                    for i, b in enumerate(activity_branches):\n",
    "                        print(i, b)\n",
    "                    \n",
    "                    # second create connections between all activities of each pair of branches \n",
    "                    for branchA, branchB in itertools.combinations(activity_branches, 2):\n",
    "                        for e1, e2 in itertools.product(*[branchA, branchB]):\n",
    "                            if e1[3] == ACTIVITY and e2[3] == ACTIVITY:  # omit gateways or condition specs\n",
    "                                relations.append((doc_name, e1, e2, EXCLUSIVE if gateway[3] == XOR_GATEWAY else CONCURRENT, \"branches\"))\n",
    "\n",
    "                # TODO: cases where gateway is at the start of the document\n",
    "                # TODO: one branch gateways\n",
    "\n",
    "    # filter duplicates & sort\n",
    "    relations_final = []\n",
    "    for r in relations:\n",
    "        if r not in relations_final:\n",
    "            relations_final.append(r)\n",
    "    relations_final.sort(key=lambda r: (r[1][0], r[1][1], r[2][0], r[2][1]))\n",
    "\n",
    "    return relations_final\n",
    "            \n",
    "\n",
    "\n",
    "    \n",
    "activity_relations = data_generation(['doc-1.1'], whole_branch_pairs=True)\n",
    "print(\" RESULTS \".center(100, '-'))\n",
    "for relation in activity_relations:\n",
    "    print(relation)\n",
    "print(\"relations:\", len(activity_relations))\n",
    "# check again: doc-1.2; doc-6.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
