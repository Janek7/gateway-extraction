{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02f1a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dir to sys path for import of modules\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "# find recursively the project root dir\n",
    "parent_dir = str(os.getcwdb())\n",
    "while not os.path.exists(os.path.join(parent_dir, \"README.md\")):\n",
    "    parent_dir = os.path.abspath(os.path.join(parent_dir, os.pardir))\n",
    "sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b9ab740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import itertools\n",
    "from typing import List, Tuple\n",
    "\n",
    "from petreader.labels import *\n",
    "\n",
    "from PetReader import pet_reader\n",
    "from utils import GatewayExtractionException\n",
    "\n",
    "\n",
    "logger = logging.getLogger('Data Generation: Activity Relations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "65b458b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = 'directly_following'\n",
    "EXCLUSIVE = 'exclusive'\n",
    "CONCURRENT = 'concurrent'\n",
    "NON_RELATED = 'non_related'\n",
    "\n",
    "DOC_START = 'Document Start'\n",
    "\n",
    "SOURCE = 'source'\n",
    "TARGET = 'target'\n",
    "\n",
    "doc_black_list = ['doc-6.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8dbd9f1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------ FLOW RELATIONS ------------------------------------------\n",
      "\n",
      "\n",
      "0 (-1, -1, None, 'Document Start') (1, 4, ['receives'], 'Activity')\n",
      "\n",
      "\n",
      "1 (1, 4, ['receives'], 'Activity') (2, 9, ['or'], 'XOR Gateway')\n",
      "... opened additionally (9, 0, ['In', 'the', 'meantime'], 'AND Gateway')\n",
      "... opened additionally (6, 0, ['If'], 'XOR Gateway')\n",
      "... closed (10, 0, ['If'], 'XOR Gateway')\n",
      "... closed (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (2, 9, ['or'], 'XOR Gateway') - merge point: None\n",
      "Branch 0: [(2, 8, ['reject'], 'Activity')]\n",
      "Branch 1: [(2, 10, ['accept'], 'Activity'), (4, 12, ['informed'], 'Activity'), (9, 0, ['In', 'the', 'meantime'], 'AND Gateway'), (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), (9, 0, ['In', 'the', 'meantime'], 'AND Gateway'), (5, 11, ['checks'], 'Activity'), (6, 0, ['If'], 'XOR Gateway'), (7, 0, ['If'], 'XOR Gateway'), (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification'), (7, 8, ['back-ordered'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), (10, 0, ['If'], 'XOR Gateway'), (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification'), (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "2 (2, 9, ['or'], 'XOR Gateway') (2, 8, ['reject'], 'Activity')\n",
      "\n",
      "\n",
      "3 (2, 9, ['or'], 'XOR Gateway') (2, 10, ['accept'], 'Activity')\n",
      "\n",
      "\n",
      "4 (2, 10, ['accept'], 'Activity') (4, 12, ['informed'], 'Activity')\n",
      "\n",
      "\n",
      "5 (4, 12, ['informed'], 'Activity') (9, 0, ['In', 'the', 'meantime'], 'AND Gateway')\n",
      "... opened additionally (6, 0, ['If'], 'XOR Gateway')\n",
      "... closed (10, 0, ['If'], 'XOR Gateway')\n",
      "... closed (10, 0, ['If'], 'XOR Gateway')\n",
      "Gateway (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "Branch 0: [(9, 7, ['prepares'], 'Activity')]\n",
      "Branch 1: [(5, 3, ['processes'], 'Activity'), (5, 11, ['checks'], 'Activity'), (6, 0, ['If'], 'XOR Gateway'), (7, 0, ['If'], 'XOR Gateway'), (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity'), (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification'), (7, 8, ['back-ordered'], 'Activity'), (6, 0, ['If'], 'XOR Gateway'), (7, 0, ['If'], 'XOR Gateway'), (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification'), (6, 9, ['reserved'], 'Activity'), (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification'), (7, 8, ['back-ordered'], 'Activity')]\n",
      "\n",
      "\n",
      "6 (5, 3, ['processes'], 'Activity') (5, 11, ['checks'], 'Activity')\n",
      "\n",
      "\n",
      "7 (5, 11, ['checks'], 'Activity') (6, 0, ['If'], 'XOR Gateway')\n",
      "... closed (10, 0, ['If'], 'XOR Gateway')\n",
      "Gateway (6, 0, ['If'], 'XOR Gateway') - merge point: (10, 0, ['If'], 'XOR Gateway')\n",
      "same gateway (7, 0, ['If'], 'XOR Gateway') linked entities: [(7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification')]\n",
      "Branch 0: [(6, 9, ['reserved'], 'Activity')]\n",
      "Branch 1: [(7, 8, ['back-ordered'], 'Activity')]\n",
      "\n",
      "\n",
      "8 (6, 0, ['If'], 'XOR Gateway') (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification')\n",
      "\n",
      "\n",
      "9 (6, 1, ['the', 'part', 'is', 'available', 'in-house'], 'Condition Specification') (6, 9, ['reserved'], 'Activity')\n",
      "\n",
      "\n",
      "10 (6, 9, ['reserved'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "Branch 0: [(10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "11 (7, 0, ['If'], 'XOR Gateway') (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification')\n",
      "\n",
      "\n",
      "12 (7, 1, ['it', 'is', 'not', 'available'], 'Condition Specification') (7, 8, ['back-ordered'], 'Activity')\n",
      "\n",
      "\n",
      "13 (7, 8, ['back-ordered'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "Branch 0: [(10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "14 (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') (9, 7, ['prepares'], 'Activity')\n",
      "\n",
      "\n",
      "15 (9, 0, ['In', 'the', 'meantime'], 'AND Gateway') (5, 3, ['processes'], 'Activity')\n",
      "\n",
      "\n",
      "16 (9, 7, ['prepares'], 'Activity') (10, 0, ['If'], 'XOR Gateway')\n",
      "WARNING: no merge point found\n",
      "Gateway (10, 0, ['If'], 'XOR Gateway') - merge point: None\n",
      "Branch 0: [(10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity')]\n",
      "\n",
      "\n",
      "17 (10, 0, ['If'], 'XOR Gateway') (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification')\n",
      "\n",
      "\n",
      "18 (10, 1, ['the', 'storehouse', 'has', 'successfully', 'reserved', 'or', 'back-ordered', 'every', 'item', 'of', 'the', 'part', 'list'], 'Condition Specification') (10, 24, ['assembles'], 'Activity')\n",
      "\n",
      "\n",
      "19 (10, 24, ['assembles'], 'Activity') (11, 5, ['ships'], 'Activity')\n",
      "--------------------------------------------- RESULTS ----------------------------------------------\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (2, 8, ['reject'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (2, 10, ['accept'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (2, 10, ['accept'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 8, ['reject'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'directly_following', 'g -> a')\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'directly_following', 'g -> sg -> cond -> a')\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'exclusive', 'branches')\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (7, 8, ['back-ordered'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'concurrent', 'branches')\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'directly_following', 'g -> cond -> a')\n",
      "('doc-1.1', (10, 24, ['assembles'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'directly_following', 'normal df')\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (4, 12, ['informed'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (1, 4, ['receives'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (5, 3, ['processes'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (2, 10, ['accept'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (5, 11, ['checks'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (4, 12, ['informed'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (6, 9, ['reserved'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (7, 8, ['back-ordered'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 3, ['processes'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (10, 24, ['assembles'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (5, 11, ['checks'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (6, 9, ['reserved'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (7, 8, ['back-ordered'], 'Activity'), (9, 7, ['prepares'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (7, 8, ['back-ordered'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "('doc-1.1', (9, 7, ['prepares'], 'Activity'), (11, 5, ['ships'], 'Activity'), 'non_related', None)\n",
      "relations normal: 26\n",
      "relations non_related: 33\n"
     ]
    }
   ],
   "source": [
    "def transform_relations(relations):\n",
    "    results = [{SOURCE: (r[SOURCE_SENTENCE_ID], r[SOURCE_HEAD_TOKEN_ID], r[SOURCE_ENTITY], r[SOURCE_ENTITY_TYPE]),\n",
    "                TARGET: (r[TARGET_SENTENCE_ID], r[TARGET_HEAD_TOKEN_ID], r[TARGET_ENTITY], r[TARGET_ENTITY_TYPE])}\n",
    "               for r in relations]\n",
    "    return results\n",
    "\n",
    "def unique_ordered_flows(flows):\n",
    "    flows_u = []\n",
    "    for f in flows:\n",
    "        if f not in flows_u:\n",
    "            flows_u.append(f)\n",
    "    flows_u.sort(key=lambda f: (f[SOURCE][0], f[SOURCE][1]))\n",
    "    return flows_u\n",
    "\n",
    "def get_linked_entities(gateway, flow_relations):\n",
    "    return [r[TARGET] for r in flow_relations if r[SOURCE] == gateway]\n",
    "\n",
    "def get_linked_entities_via_condition(gateway, flow_relations):\n",
    "    return [[r2[TARGET] for r2 in flow_relations if r2[SOURCE] == r[TARGET]][0]\n",
    "            for r in flow_relations if r[SOURCE] == gateway and r[TARGET][3] == CONDITION_SPECIFICATION]\n",
    "\n",
    "def get_sg_gateways(gateway, sg_relations):\n",
    "    \"\"\"\n",
    "    search for gateways that are related to the given gateway via a same gateway relation\n",
    "    search is conducted recursively to support multi branch gateways (>2 branches)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for sg in sg_relations:\n",
    "        if sg[SOURCE] == gateway:\n",
    "            results.append(sg[TARGET])\n",
    "            recursive_gateways = get_sg_gateways(sg[TARGET], sg_relations)\n",
    "            if recursive_gateways:\n",
    "                results.extend(recursive_gateways)\n",
    "    return results\n",
    "\n",
    "def get_following_flows_by_text_structure(element, flow_relations):\n",
    "    return [f for f in flow_relations if f[SOURCE][0] > element[0] \n",
    "                                      or (f[SOURCE][0] == element[0] and f[SOURCE][1] >= element[1])]\n",
    "\n",
    "def get_previous_flows_by_text_structure(element, flow_relations):\n",
    "    return [f for f in flow_relations if f[SOURCE][0] < element[0] \n",
    "                                      or (f[SOURCE][0] == element[0] and f[SOURCE][1] <= element[1])]\n",
    "\n",
    "def get_number_incoming_flows(element, flow_relations):\n",
    "    return len([f for f in flow_relations if f[TARGET] == element])\n",
    "\n",
    "def get_number_outgoing_flows(element, flow_relations):\n",
    "    return len([f for f in flow_relations if f[SOURCE] == element])\n",
    "\n",
    "def get_merge_point_search_flows(element, flow_relations):\n",
    "    # start with flows following by text structure\n",
    "    following_flows = get_following_flows_by_text_structure(element, flow_relations)\n",
    "    \n",
    "    # check for other flows of the target element before because order in text can differ from process logic order\n",
    "    additional_flows = []\n",
    "    for f in following_flows:\n",
    "        additional_flows.extend(get_following_flows_by_text_structure(f[TARGET], flow_relations))\n",
    "        \n",
    "    # add flows ongoing from directly linked activities because structure in text can be different then process structure (e.g. doc-1.1 parallel gateway)\n",
    "    directy_linked_entities = get_linked_entities(element, flow_relations)\n",
    "    for e in directy_linked_entities:\n",
    "        additional_flows.extend(get_following_flows_by_text_structure(e, flow_relations))\n",
    "        \n",
    "    flows = unique_ordered_flows(following_flows + additional_flows)\n",
    "    flows_filtered = []\n",
    "    for f in flows:\n",
    "        if f[TARGET] != element:\n",
    "            flows_filtered.append(f)\n",
    "    \n",
    "    return flows_filtered\n",
    "\n",
    "\n",
    "nested_gateways = []\n",
    "\n",
    "def find_next_merge_point(doc_name, element, flow_relations):\n",
    "    \"\"\"\n",
    "    find next activity that has multiple incoming flows (i.e. merge point) \n",
    "    \"\"\"\n",
    "    relevant_flows = get_merge_point_search_flows(element, flow_relations)\n",
    "    \n",
    "    next_targets = []\n",
    "    unclosed_gateways = 1\n",
    "    for f in relevant_flows:\n",
    "        # another gateway opened that has to be closed first\n",
    "        # check for incoming flows == 1 because with > 1 gateway is merge point as well\n",
    "        if f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY] and get_number_incoming_flows(f[TARGET], flow_relations) == 1:\n",
    "            unclosed_gateways += 1\n",
    "            print(f\"... opened additionally {f[TARGET]}\")\n",
    "            \n",
    "            tmp = {\"doc_name\": doc_name, \"parent\": element, \"nested_gateway\": f[TARGET]}\n",
    "            if tmp not in nested_gateways:\n",
    "                nested_gateways.append(tmp)\n",
    "            \n",
    "#         if get_number_outgoing_flows(f[TARGET], flow_relations) == 0: (works only for doc-6.4)\n",
    "#             unclosed_gateways -= 1\n",
    "#             print(f\"... closed one because of process end in the middle of the process {f[TARGET]}\")\n",
    "        if f[TARGET] in next_targets:\n",
    "            # one closing found\n",
    "            unclosed_gateways -= 1\n",
    "            print(f\"... closed {f[TARGET]}\")\n",
    "            # check if all opened gateways are closed\n",
    "            if unclosed_gateways == 0:\n",
    "                return f[TARGET]\n",
    "        else:\n",
    "            next_targets.append(f[TARGET])\n",
    "    print(\"WARNING: no merge point found\")\n",
    "    return None\n",
    "\n",
    "def get_following_flows(element, flow_relations, same_gateway_relations):\n",
    "    # start with flows following by text structure\n",
    "    following_flows = get_following_flows_by_text_structure(element, flow_relations)\n",
    "    \n",
    "    for f in following_flows:\n",
    "        # check for links to same gateways and their following activities/branches\n",
    "        if f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY]:\n",
    "            sg_gateways = get_sg_gateways(f[TARGET], same_gateway_relations)\n",
    "            for same_gateway in sg_gateways:\n",
    "                sg_following_flows = get_following_flows(same_gateway, flow_relations, same_gateway_relations)\n",
    "                following_flows.extend(sg_following_flows)\n",
    "                \n",
    "    return unique_ordered_flows(following_flows)\n",
    "\n",
    "def get_entities_until_merge_point(element, next_merge, flow_relations, same_gateway_relations):\n",
    "    \"\"\"\n",
    "    return all entities between given element and next given merge point based on flow relations/connections\n",
    "    if merge point is None, return all entities until the end\n",
    "    \"\"\"\n",
    "    relevant_flows = get_following_flows(element, flow_relations, same_gateway_relations)\n",
    "    entities_between = [element]\n",
    "\n",
    "    # iterate twice because semantical structure does not always follows textual structure AND because of same gateways\n",
    "    # -> in first run maybe not all are captured\n",
    "    # duplicates will be created, but filtered after again\n",
    "    def dummy():\n",
    "        for f in flow_relations:\n",
    "            # if source of new flow is in already recorded elements and (no merge exist or target is before merge)\n",
    "            if f[SOURCE] in entities_between \\\n",
    "                and (not next_merge or \\\n",
    "                     (f[TARGET][0] < next_merge[0] or (f[TARGET][0] == next_merge[0] and f[TARGET][1] < next_merge[1]))):\n",
    "                entities_between.append(f[TARGET])\n",
    "                \n",
    "                if f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY]:\n",
    "                    entities_between.extend(get_sg_gateways(f[TARGET], same_gateway_relations))\n",
    "                    \n",
    "    dummy()\n",
    "    # remove start element\n",
    "    entities_between = entities_between[1:]\n",
    "    dummy()\n",
    "    \n",
    "    # make unique again\n",
    "    entities_between_u = []\n",
    "    for a in entities_between:\n",
    "        if a not in entities_between_u:\n",
    "            entities_between_u.append(a)\n",
    "    \n",
    "    return entities_between\n",
    "\n",
    "def get_last_activities(flow, flow_relations):\n",
    "    \"\"\"\n",
    "    search for last (transitively) linked activities (recursively) before current flow\n",
    "    :param flow: flow to start reversed search for\n",
    "    :param flow_relations: set of flows\n",
    "    :return: list of transitive connected activities\n",
    "    \"\"\"\n",
    "    last_activities = []\n",
    "    relevant_flows = get_previous_flows_by_text_structure(flow[SOURCE], flow_relations)\n",
    "    last_element = flow[SOURCE]\n",
    "    \n",
    "    # search from this flow to search reversed for last activities    \n",
    "    while not last_activities:\n",
    "        source_flows = [f for f in relevant_flows if f[TARGET] == last_element]\n",
    "        temp_new_activities = []\n",
    "        for source_flow in source_flows:\n",
    "            # a) base case -> activity found\n",
    "            if source_flow[SOURCE][3] == ACTIVITY:\n",
    "                temp_new_activities.append(source_flow[SOURCE])\n",
    "            # b) recursive case -> continue search from flow before\n",
    "            else:\n",
    "                temp_new_activities.extend(get_last_activities(source_flow, relevant_flows))\n",
    "        last_activities.extend(temp_new_activities)\n",
    "        \n",
    "    return last_activities\n",
    "\n",
    "def enrich_doc_start_flow(flow_relations):\n",
    "    new_first_flow = {SOURCE: (-1, -1, None, DOC_START), TARGET: flow_relations[0][SOURCE]}\n",
    "    return [new_first_flow] + flow_relations\n",
    "\n",
    "def filter_merge_point(merge_point, entity_list):\n",
    "    return [e for e in entity_list if e != merge_point]\n",
    "\n",
    "def filter_cond_spec(entity_list):\n",
    "    return [e for e in entity_list if e[3] != CONDITION_SPECIFICATION]\n",
    "\n",
    "\n",
    "def create_branch_relations(doc_name, flow_relations, same_gateway_relations, gateway, merge_point, branch_start_entities):\n",
    "    \"\"\"\n",
    "    create all relations between all entities of all combinations of branches\n",
    "    :param branch_start_entities:\n",
    "    :return: list of relations in tuple format\n",
    "    \"\"\"\n",
    "    relations = []\n",
    "    # add exclusive/concurrent relations between (multiple) activities of branches\n",
    "    # first create list of activities for each branch\n",
    "    # exclude merge point because its not part of exclusive/concurrent relations\n",
    "    activity_branches = ([[e] + (get_entities_until_merge_point(e, merge_point, flow_relations, same_gateway_relations))\n",
    "                           for e in filter_merge_point(merge_point, branch_start_entities)])\n",
    "    \n",
    "    for i, b in enumerate(activity_branches):\n",
    "        print(f\"Branch {i}: {b}\")\n",
    "\n",
    "    # second create connections between all activities of each pair of branches\n",
    "    if activity_branches:\n",
    "        for branchA, branchB in itertools.combinations(activity_branches, 2):\n",
    "            for e1, e2 in itertools.product(*[branchA, branchB]):\n",
    "                if e1[3] == ACTIVITY and e2[3] == ACTIVITY:  # omit gateways or condition specs\n",
    "                    relations.append((doc_name, e1, e2,\n",
    "                                      EXCLUSIVE if gateway[3] == XOR_GATEWAY else CONCURRENT, \"branches\"))\n",
    "\n",
    "    return relations\n",
    "\n",
    "def flatten_list(two_dim_list: List[List]) -> List:\n",
    "    \"\"\"\n",
    "    flattens a two dimensional list\n",
    "    :param two_dim_list: nested list\n",
    "    :return: not nested list\n",
    "    \"\"\"\n",
    "    return [item for sublist in two_dim_list for item in sublist]\n",
    "\n",
    "def create_non_related_relations(doc_name: str, normal_relations: List[Tuple]) -> List[Tuple]:\n",
    "    # get all activities of a document and transfer to internal format\n",
    "    doc_activites = pet_reader.get_index_enriched_activities(doc_name)    \n",
    "    doc_activites = [[(i, a[1], a[0], ACTIVITY) for a in sentence_activities] for i, sentence_activities in enumerate(doc_activites)]\n",
    "    doc_activites = flatten_list(doc_activites)\n",
    "    \n",
    "    # create relations between all pairs that do not have a relation assigned yet\n",
    "    new_relations = []\n",
    "    for a1, a2 in itertools.combinations(doc_activites, 2):\n",
    "        normal_relations_filtered = list(filter(lambda r: r[1] == a1 and r[2] == a2, normal_relations))\n",
    "        if not normal_relations_filtered:\n",
    "            new_relations.append((doc_name, a1, a2, NON_RELATED, None))\n",
    "    return new_relations\n",
    "\n",
    "\n",
    "def data_generation(doc_names, whole_branch_pairs=True, drop_loops: bool = True):\n",
    "    \n",
    "    # data format -> (doc_name, (a1), (a2), type, comment)\n",
    "    # split/merge points are represented as directly follow relations \n",
    "    relations = []\n",
    "    \n",
    "    for i, doc_name in enumerate(pet_reader.document_names):\n",
    "        doc_relations = []\n",
    "\n",
    "        if (doc_names and doc_name not in doc_names) or doc_name in doc_black_list:\n",
    "            continue\n",
    "            \n",
    "        # 1) Search for relations using gateways\n",
    "        pet_relations = pet_reader.relations_dataset.GetRelations(pet_reader.get_document_number(doc_name))\n",
    "        flow_relations = transform_relations(pet_relations[FLOW])\n",
    "        flow_relations = enrich_doc_start_flow(flow_relations)\n",
    "        same_gateway_relations = transform_relations(pet_relations[SAME_GATEWAY])\n",
    "        \n",
    "        # special case: remove flows that causes process loops\n",
    "        if drop_loops:\n",
    "            if doc_name == 'doc-9.5':\n",
    "                flow_relations = flow_relations[:-1]\n",
    "            if doc_name == 'doc-2.1':\n",
    "                flow_relations.remove({'source': (7, 2, ['the', 'customer', 'is', 'of', 'certain', 'significance'], 'Condition Specification'), \n",
    "                                       'target': (5, 4, ['determines'], 'Activity')})\n",
    "            if doc_name == 'doc-2.2':\n",
    "                flow_relations.remove({'source': (12, 5, ['generated'], 'Activity'), \n",
    "                                       'target': (10, 5, ['check'], 'Activity')})\n",
    "                    \n",
    "        print(\" FLOW RELATIONS \".center(100, '-'))\n",
    "        \n",
    "        for i, f in enumerate(flow_relations):\n",
    "            print(\"\\n\")\n",
    "            print(i, f[SOURCE], f[TARGET])\n",
    "            \n",
    "            # a) DIRECTLY FOLLOWING RELATIONS\n",
    "            if f[SOURCE][3] == f[TARGET][3] == ACTIVITY:\n",
    "                doc_relations.append((doc_name, f[SOURCE], f[TARGET], DF, \"normal df\"))\n",
    "                \n",
    "            # b) RELATIONS INVOLVING GATEWAYS\n",
    "            if f[TARGET][3] in [XOR_GATEWAY, AND_GATEWAY]:\n",
    "                \n",
    "                # extract source activity of current flow for linking pairing with following activities of gateway (f[TARGET]) \n",
    "                if f[SOURCE][3] == ACTIVITY:\n",
    "                    source_activities = [f[SOURCE]]\n",
    "                # if gateways are nested/referring each other -> lookup previous last normal activity recursively\n",
    "                elif f[SOURCE][3] in [CONDITION_SPECIFICATION, XOR_GATEWAY, AND_GATEWAY]:\n",
    "                    source_activities = get_last_activities(f, flow_relations)\n",
    "                    print(f\"Nested gateway - transitive last activities: {source_activities}\")\n",
    "                # if gateway is at document start, no flows from connected activities of gateway to any source activities can be created\n",
    "                elif f[SOURCE][3] == DOC_START:\n",
    "                    source_activities = []\n",
    "                else:\n",
    "                    raise GatewayExtractionException(\"Other flow combination!\")\n",
    "                    \n",
    "                \n",
    "                gateway = f[TARGET]\n",
    "                gateway_merge_point = find_next_merge_point(doc_name, gateway, flow_relations)\n",
    "                branch_start_entities = []\n",
    "                print(f\"Gateway {gateway} - merge point: {gateway_merge_point}\")\n",
    "                \n",
    "                # create flows from possible multiple incomes to current gateway (only in case of directly nested gateways)\n",
    "                # to possible multiple outcomes (normal for gateways)\n",
    "                \n",
    "                # extract activities to which the gateway refers\n",
    "\n",
    "                \n",
    "                # - 1) in case of direct entity (activity or further gateway) link without conditon and same gateway\n",
    "                # cases: exlusive 'or' gateways || parallel gateways\n",
    "                directly_linked_entities = get_linked_entities(gateway, flow_relations)\n",
    "                directly_linked_entities\n",
    "                # add relations of activities before to (directly linked) gateway activities via DF\n",
    "                for e in directly_linked_entities:\n",
    "                    if e[3] == ACTIVITY:\n",
    "                        for source_activity in source_activities:\n",
    "                            doc_relations.append((doc_name, source_activity, e, DF, \"g -> a\"))\n",
    "                directly_linked_entities_filtered = filter_merge_point(gateway_merge_point, directly_linked_entities)\n",
    "                directly_linked_entities_filtered = filter_cond_spec(directly_linked_entities_filtered)\n",
    "                branch_start_entities.extend(directly_linked_entities_filtered)\n",
    "\n",
    "                # - 2) in case of indirect link via condition specification or same gateway relations\n",
    "                gateway_branches_entities_directly_linked = []\n",
    "                condition_spec_linked = get_linked_entities_via_condition(gateway, flow_relations)\n",
    "                for e in condition_spec_linked:\n",
    "                    if e[3] == ACTIVITY:\n",
    "                        for source_activity in source_activities:\n",
    "                            doc_relations.append((doc_name, source_activity, e, DF, \"g -> cond -> a\")) \n",
    "                        gateway_branches_entities_directly_linked.append(e)\n",
    "                    # not activity is linked, but other (gateway, cond) from which following activities will be included as well\n",
    "                    else:\n",
    "                        gateway_branches_entities_directly_linked.append(e)\n",
    "                branch_start_entities.extend(gateway_branches_entities_directly_linked)\n",
    "\n",
    "                # - 3) detect same gateways and repeat procedure for them\n",
    "                sg_entities_linked = []\n",
    "                sg_gateways = get_sg_gateways(gateway, same_gateway_relations)\n",
    "                for sg_gateway in sg_gateways:\n",
    "                    # directly linked\n",
    "                    sg_linked_entities = get_linked_entities(sg_gateway, flow_relations)\n",
    "                    print(\"same gateway\", sg_gateway, \"linked entities:\", sg_linked_entities)\n",
    "                    for e in sg_linked_entities:\n",
    "                        if e[3] == ACTIVITY:\n",
    "                            for source_activity in source_activities:\n",
    "                                doc_relations.append((doc_name, source_activity, e, DF, \"g -> sg -> a\"))\n",
    "                            sg_entities_linked.append(e)\n",
    "                        # not activity is linked, but other gateway from which following activities will be included as well\n",
    "                        elif e[3] in [XOR_GATEWAY, AND_GATEWAY]:\n",
    "                            sg_entities_linked.append(e)\n",
    "                    # linked via condition\n",
    "                    try:\n",
    "                        sg_gateway_condition_spec_linked = get_linked_entities_via_condition(sg_gateway, flow_relations)\n",
    "                        for e in sg_gateway_condition_spec_linked:\n",
    "                            if e[3] == ACTIVITY:\n",
    "                                for source_activity in source_activities:\n",
    "                                    doc_relations.append((doc_name, source_activity, e, DF, \"g -> sg -> cond -> a\"))\n",
    "                                sg_entities_linked.append(e)\n",
    "                            # not activity is linked, but other (gateway, cond) from which following activities will be included as well\n",
    "                            else:\n",
    "                                sg_entities_linked.append(e)\n",
    "                    except IndexError:\n",
    "                        # in case of 2.1 were relation is removed due to loop -> just skip this branch\n",
    "                        pass\n",
    "                branch_start_entities.extend(sg_entities_linked)\n",
    "                \n",
    "                # Create relations between activities of all branches\n",
    "                doc_relations.extend(create_branch_relations(doc_name, flow_relations, same_gateway_relations, \n",
    "                                                             gateway, gateway_merge_point, branch_start_entities))\n",
    "        \n",
    "        # add relations of type 'non_related' between all so far unrelated activities in the document\n",
    "        doc_relations.extend(create_non_related_relations(doc_name, doc_relations))\n",
    "        \n",
    "        relations.extend(doc_relations)\n",
    "\n",
    "    # filter duplicates & sort\n",
    "    relations_final = []\n",
    "    for r in relations:\n",
    "        # check if pair (order of gateways doesnt matter) is already in set\n",
    "        if r not in relations_final and (r[0], r[2], r[1], r[3], r[4]) not in relations_final and r[1] != r[2]:\n",
    "            relations_final.append(r)\n",
    "    relations_final.sort(key=lambda r: (r[0], not (r[3] != NON_RELATED), r[1][0], r[1][1], r[2][0], r[2][1]))\n",
    "    \n",
    "    return relations_final\n",
    "\n",
    "    \n",
    "activity_relations = data_generation(['doc-1.1'], whole_branch_pairs=True)\n",
    "print(\" RESULTS \".center(100, '-'))\n",
    "for relation in activity_relations:\n",
    "    print(relation)\n",
    "print(\"relations normal:\", len([r for r in activity_relations if r[3] != NON_RELATED]))\n",
    "print(\"relations non_related:\", len([r for r in activity_relations if r[3] == NON_RELATED]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
